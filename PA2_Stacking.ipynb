{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Activity - Stacking\n",
    "## Nick Bias \n",
    "### 4/13/22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# compare ensemble to each standalone models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in original data, Spliting Prediction Variable from dataset,  Creating Dummy Variables for Sex, and Merging Data\n",
    "- X = Dataset with all Independent Variables \n",
    "- y = The Dependent Variable of how many Rings the Abalone have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>whole_weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      length  diameter  height  whole_weight  shucked_weight  viscera_weight  \\\n",
       "0      0.455     0.365   0.095        0.5140          0.2245          0.1010   \n",
       "1      0.350     0.265   0.090        0.2255          0.0995          0.0485   \n",
       "2      0.530     0.420   0.135        0.6770          0.2565          0.1415   \n",
       "3      0.440     0.365   0.125        0.5160          0.2155          0.1140   \n",
       "4      0.330     0.255   0.080        0.2050          0.0895          0.0395   \n",
       "...      ...       ...     ...           ...             ...             ...   \n",
       "4172   0.565     0.450   0.165        0.8870          0.3700          0.2390   \n",
       "4173   0.590     0.440   0.135        0.9660          0.4390          0.2145   \n",
       "4174   0.600     0.475   0.205        1.1760          0.5255          0.2875   \n",
       "4175   0.625     0.485   0.150        1.0945          0.5310          0.2610   \n",
       "4176   0.710     0.555   0.195        1.9485          0.9455          0.3765   \n",
       "\n",
       "      shell_weight  F  I  M  \n",
       "0           0.1500  0  0  1  \n",
       "1           0.0700  0  0  1  \n",
       "2           0.2100  1  0  0  \n",
       "3           0.1550  0  0  1  \n",
       "4           0.0550  0  1  0  \n",
       "...            ... .. .. ..  \n",
       "4172        0.2490  1  0  0  \n",
       "4173        0.2605  0  0  1  \n",
       "4174        0.3080  0  0  1  \n",
       "4175        0.2960  1  0  0  \n",
       "4176        0.4950  0  0  1  \n",
       "\n",
       "[4177 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone_data = pd.read_csv(\"Data/Week3/abalone.csv\")\n",
    "y = abalone_data['rings']\n",
    "abalone_data2 = abalone_data.iloc[:,1:-1]\n",
    "abalone_sex = pd.get_dummies(abalone_data['sex'])\n",
    "X = pd.merge(abalone_data2, abalone_sex, left_index=True, right_index=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LinearRegression()))\n",
    "    level0.append(('knn', KNeighborsRegressor()))\n",
    "    level0.append(('cart', DecisionTreeRegressor()))\n",
    "    level0.append(('svm', SVR()))\n",
    "    # define meta learner model\n",
    "    level1 = LinearRegression()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5, passthrough = True)\n",
    "    return model\n",
    "# passthrough is used for the stacking to take the og dataset instead of just the other model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LinearRegression()\n",
    "    models['knn'] = KNeighborsRegressor()\n",
    "    models['cart'] = DecisionTreeRegressor()\n",
    "    models['svm'] = SVR()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the models to evaluate\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr -1.585 (0.078)\n",
      ">knn -1.574 (0.071)\n",
      ">cart -2.096 (0.115)\n",
      ">svm -1.534 (0.085)\n",
      ">stacking -1.523 (0.072)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Models performed about the same except the Decision Tree Regression was noticeably worst. Stacking was best meta-model, but only by 0.01 more than SVM. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

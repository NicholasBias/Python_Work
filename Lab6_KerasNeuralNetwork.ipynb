{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Keras Neural Networks\n",
    "## Nick Bias\n",
    "### 5/16/22\n",
    "## Goal: Predict Diabetes\n",
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Needed for Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import layers\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For other model to compare with \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# For Evaluations \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# So results are same when re-run\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "# This helps display all columns when looking at dataset\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "      <td>70692.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.563458</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>0.975259</td>\n",
       "      <td>29.856985</td>\n",
       "      <td>0.475273</td>\n",
       "      <td>0.062171</td>\n",
       "      <td>0.147810</td>\n",
       "      <td>0.703036</td>\n",
       "      <td>0.611795</td>\n",
       "      <td>0.788774</td>\n",
       "      <td>0.042721</td>\n",
       "      <td>0.954960</td>\n",
       "      <td>0.093914</td>\n",
       "      <td>2.837082</td>\n",
       "      <td>3.752037</td>\n",
       "      <td>5.810417</td>\n",
       "      <td>0.252730</td>\n",
       "      <td>0.456997</td>\n",
       "      <td>8.584055</td>\n",
       "      <td>4.920953</td>\n",
       "      <td>5.698311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500004</td>\n",
       "      <td>0.495960</td>\n",
       "      <td>0.499342</td>\n",
       "      <td>0.155336</td>\n",
       "      <td>7.113954</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>0.241468</td>\n",
       "      <td>0.354914</td>\n",
       "      <td>0.456924</td>\n",
       "      <td>0.487345</td>\n",
       "      <td>0.408181</td>\n",
       "      <td>0.202228</td>\n",
       "      <td>0.207394</td>\n",
       "      <td>0.291712</td>\n",
       "      <td>1.113565</td>\n",
       "      <td>8.155627</td>\n",
       "      <td>10.062261</td>\n",
       "      <td>0.434581</td>\n",
       "      <td>0.498151</td>\n",
       "      <td>2.852153</td>\n",
       "      <td>1.029081</td>\n",
       "      <td>2.175196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary        HighBP      HighChol     CholCheck  \\\n",
       "count     70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean          0.500000      0.563458      0.525703      0.975259   \n",
       "std           0.500004      0.495960      0.499342      0.155336   \n",
       "min           0.000000      0.000000      0.000000      0.000000   \n",
       "25%           0.000000      0.000000      0.000000      1.000000   \n",
       "50%           0.500000      1.000000      1.000000      1.000000   \n",
       "75%           1.000000      1.000000      1.000000      1.000000   \n",
       "max           1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                BMI        Smoker        Stroke  HeartDiseaseorAttack  \\\n",
       "count  70692.000000  70692.000000  70692.000000          70692.000000   \n",
       "mean      29.856985      0.475273      0.062171              0.147810   \n",
       "std        7.113954      0.499392      0.241468              0.354914   \n",
       "min       12.000000      0.000000      0.000000              0.000000   \n",
       "25%       25.000000      0.000000      0.000000              0.000000   \n",
       "50%       29.000000      0.000000      0.000000              0.000000   \n",
       "75%       33.000000      1.000000      0.000000              0.000000   \n",
       "max       98.000000      1.000000      1.000000              1.000000   \n",
       "\n",
       "       PhysActivity        Fruits       Veggies  HvyAlcoholConsump  \\\n",
       "count  70692.000000  70692.000000  70692.000000       70692.000000   \n",
       "mean       0.703036      0.611795      0.788774           0.042721   \n",
       "std        0.456924      0.487345      0.408181           0.202228   \n",
       "min        0.000000      0.000000      0.000000           0.000000   \n",
       "25%        0.000000      0.000000      1.000000           0.000000   \n",
       "50%        1.000000      1.000000      1.000000           0.000000   \n",
       "75%        1.000000      1.000000      1.000000           0.000000   \n",
       "max        1.000000      1.000000      1.000000           1.000000   \n",
       "\n",
       "       AnyHealthcare   NoDocbcCost       GenHlth      MentHlth      PhysHlth  \\\n",
       "count   70692.000000  70692.000000  70692.000000  70692.000000  70692.000000   \n",
       "mean        0.954960      0.093914      2.837082      3.752037      5.810417   \n",
       "std         0.207394      0.291712      1.113565      8.155627     10.062261   \n",
       "min         0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%         1.000000      0.000000      2.000000      0.000000      0.000000   \n",
       "50%         1.000000      0.000000      3.000000      0.000000      0.000000   \n",
       "75%         1.000000      0.000000      4.000000      2.000000      6.000000   \n",
       "max         1.000000      1.000000      5.000000     30.000000     30.000000   \n",
       "\n",
       "           DiffWalk           Sex           Age     Education        Income  \n",
       "count  70692.000000  70692.000000  70692.000000  70692.000000  70692.000000  \n",
       "mean       0.252730      0.456997      8.584055      4.920953      5.698311  \n",
       "std        0.434581      0.498151      2.852153      1.029081      2.175196  \n",
       "min        0.000000      0.000000      1.000000      1.000000      1.000000  \n",
       "25%        0.000000      0.000000      7.000000      4.000000      4.000000  \n",
       "50%        0.000000      0.000000      9.000000      5.000000      6.000000  \n",
       "75%        1.000000      1.000000     11.000000      6.000000      8.000000  \n",
       "max        1.000000      1.000000     13.000000      6.000000      8.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data50 = pd.read_csv(\"Data/Week7/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "data50.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that many of the variables are simple dummy variables, that got read in as floats. These will need to be converted for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                    0       1         0          1  26.0       0       0   \n",
       "1                    0       1         1          1  26.0       1       1   \n",
       "2                    0       0         0          1  26.0       0       0   \n",
       "3                    0       1         1          1  28.0       1       0   \n",
       "4                    0       0         0          1  29.0       1       0   \n",
       "...                ...     ...       ...        ...   ...     ...     ...   \n",
       "70687                1       0         1          1  37.0       0       0   \n",
       "70688                1       0         1          1  29.0       1       0   \n",
       "70689                1       1         1          1  25.0       0       0   \n",
       "70690                1       1         1          1  18.0       0       0   \n",
       "70691                1       1         1          1  25.0       0       0   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                         0             1       0        1                  0   \n",
       "1                         0             0       1        0                  0   \n",
       "2                         0             1       1        1                  0   \n",
       "3                         0             1       1        1                  0   \n",
       "4                         0             1       1        1                  0   \n",
       "...                     ...           ...     ...      ...                ...   \n",
       "70687                     0             0       0        1                  0   \n",
       "70688                     1             0       1        1                  0   \n",
       "70689                     1             0       1        0                  0   \n",
       "70690                     0             0       0        0                  0   \n",
       "70691                     1             1       1        0                  0   \n",
       "\n",
       "       AnyHealthcare  NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex  \\\n",
       "0                  1            0        3         5        30         0    1   \n",
       "1                  1            0        3         0         0         0    1   \n",
       "2                  1            0        1         0        10         0    1   \n",
       "3                  1            0        3         0         3         0    1   \n",
       "4                  1            0        2         0         0         0    0   \n",
       "...              ...          ...      ...       ...       ...       ...  ...   \n",
       "70687              1            0        4         0         0         0    0   \n",
       "70688              1            0        2         0         0         1    1   \n",
       "70689              1            0        5        15         0         1    0   \n",
       "70690              1            0        4         0         0         1    0   \n",
       "70691              1            0        2         0         0         0    0   \n",
       "\n",
       "       Age  Education  Income  \n",
       "0        4          6       8  \n",
       "1       12          6       8  \n",
       "2       13          6       8  \n",
       "3       11          6       8  \n",
       "4        8          5       8  \n",
       "...    ...        ...     ...  \n",
       "70687    6          4       1  \n",
       "70688   10          3       6  \n",
       "70689   13          6       4  \n",
       "70690   11          2       4  \n",
       "70691    9          6       2  \n",
       "\n",
       "[70692 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting variables that were floats to integers for analysis \n",
    "data50['Diabetes_binary'] = data50['Diabetes_binary'].astype(int)\n",
    "data50['HighBP'] = data50['HighBP'].astype(int)\n",
    "data50['HighChol'] = data50['HighChol'].astype(int)\n",
    "data50['CholCheck'] = data50['CholCheck'].astype(int)\n",
    "data50['Smoker'] = data50['Smoker'].astype(int)\n",
    "data50['Stroke'] = data50['Stroke'].astype(int)\n",
    "data50['HeartDiseaseorAttack'] = data50['HeartDiseaseorAttack'].astype(int)\n",
    "data50['PhysActivity'] = data50['PhysActivity'].astype(int)\n",
    "data50['Fruits'] = data50['Fruits'].astype(int)\n",
    "data50['Veggies'] = data50['Veggies'].astype(int)\n",
    "data50['HvyAlcoholConsump'] = data50['HvyAlcoholConsump'].astype(int)\n",
    "data50['AnyHealthcare'] = data50['AnyHealthcare'].astype(int)\n",
    "data50['NoDocbcCost'] = data50['NoDocbcCost'].astype(int)\n",
    "data50['GenHlth'] = data50['GenHlth'].astype(int)\n",
    "data50['MentHlth'] = data50['MentHlth'].astype(int)\n",
    "data50['PhysHlth'] = data50['PhysHlth'].astype(int)\n",
    "data50['DiffWalk'] = data50['DiffWalk'].astype(int)\n",
    "data50['Sex'] = data50['Sex'].astype(int)\n",
    "data50['Age'] = data50['Age'].astype(int)\n",
    "data50['Education'] = data50['Education'].astype(int)\n",
    "data50['Income'] = data50['Income'].astype(int)\n",
    "\n",
    "data50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything that was done to the previous dataset will be repeated on this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Prediction Variable from dataset\n",
    "- X = Dataset with all Independent Variables \n",
    "- y = The Dependent Variable of Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data50[\"Diabetes_binary\"]\n",
    "X = data50.drop(\"Diabetes_binary\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "Since the Target class is extremely unbalanced, We will be looking at the Precision, (proportion of positive identifications that are actually correct) and Recall (proportion of actual positives that were identified correctly). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used so it will not print all epochs\n",
    "class Callback(tf.keras.callbacks.Callback):\n",
    "    SHOW_NUMBER = 10\n",
    "    counter = 0\n",
    "    epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a Function that will Evalutate the models, by looking at Accuracy, Recall, Precision and ROC Curve\n",
    "# This will be helpful in seeing how well the target class is being predicted \n",
    "def model_eval(model, X_test, y_test):\n",
    "    assert len(X_test) == len(y_test), \"X_test and y_test are not equal in size.\"\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_prob = model.predict_proba(X_test)[::, 1]\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_pred, y_test))\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    plt.plot(fpr, tpr, label=f'AUC: {round(auc, 3)}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4979 2130]\n",
      " [1552 5478]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.76      0.73      6531\n",
      "           1       0.78      0.72      0.75      7608\n",
      "\n",
      "    accuracy                           0.74     14139\n",
      "   macro avg       0.74      0.74      0.74     14139\n",
      "weighted avg       0.74      0.74      0.74     14139\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "model_eval(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A default Random Forest Model only achieved an accuracy of about 74%. The Diabetes target class only had a Precision of 78%, which was the highest metric it achieved. The Recall is 72%. Overall, these scores are decent for a dataset of this size and complexity, however we can still test to see if Neural Networks perform better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 1s 2ms/step - loss: 0.5164 - sparse_categorical_accuracy: 0.7460\n",
      "Test loss: 0.5164164900779724\n",
      "Test accuracy: 0.7459509372711182\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=21, activation='relu')) # Default activation is relu\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001), #default learning rate = 0.001\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history_scaled = model.fit(X_train, y_train, batch_size = 64, epochs = 50, use_multiprocessing=True, callbacks=[Callback()], verbose=0) # default max iterations are 200\n",
    "\n",
    "test_scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 [==============================] - 1s 2ms/step\n",
      "[[5309 1671]\n",
      " [1921 5238]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.75      6980\n",
      "         1.0       0.76      0.73      0.74      7159\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_bool))\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 achieved an accuracy of about 75%. This is only a 1% increase than the Random Forest model. Precision is 76% for the Diabetes target class. This means that 76% diabetes identifications that are actually correct. Recall is 73%. So only 73% of actual positives diabetes that were identified correctly. These Precision and Recall scores are slightly worse than the Random Forest model. The only reason this model is better is because the Precision for non-diabetes is higher. Maybe if we increase the complexity of the Neural Network, it will perform better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 2s 3ms/step - loss: 0.6028 - accuracy: 0.7305\n",
      "Test loss: 0.602776825428009\n",
      "Test accuracy: 0.730461835861206\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=21, activation='sigmoid')) # Default activation is relu\n",
    "model.add(Dense(200, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(50, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001), #default learning rate = 0.001\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history_scaled = model.fit(X_train, y_train, batch_size = 12, epochs = 100, use_multiprocessing=True, callbacks=[Callback()], verbose=0) # default max iterations are 200\n",
    "\n",
    "test_scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1179/1179 [==============================] - 3s 3ms/step\n",
      "[[4713 2267]\n",
      " [1544 5615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.68      0.71      6980\n",
      "         1.0       0.71      0.78      0.75      7159\n",
      "\n",
      "    accuracy                           0.73     14139\n",
      "   macro avg       0.73      0.73      0.73     14139\n",
      "weighted avg       0.73      0.73      0.73     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size=12, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_bool))\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 achieved an accuracy of 73%. This is the worst performing model, however, not by much. Its recall for the diabetes is 78%, however, its precision is only 71%. Its recall for non-diabetes is 68%. So overall, this model is not a good fit for this data. Other models should be used to progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 2s 4ms/step - loss: 0.5082 - sparse_categorical_accuracy: 0.7544\n",
      "Test loss: 0.5082109570503235\n",
      "Test accuracy: 0.7543673515319824\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=21, activation='sigmoid')) # Default activation is relu\n",
    "model.add(Dense(400, activation='sigmoid'))\n",
    "model.add(Dense(400, activation='sigmoid'))\n",
    "model.add(Dense(400, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(), #default learning rate = 0.001\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history_scaled = model.fit(X_train, y_train, batch_size = 50, epochs = 100, use_multiprocessing=True, callbacks=[Callback()], verbose=0) # default max iterations are 200\n",
    "\n",
    "test_scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(\"Test loss:\", test_scores[0])\n",
    "print(\"Test accuracy:\", test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283/283 [==============================] - 2s 5ms/step\n",
      "[[4565 2415]\n",
      " [1058 6101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.65      0.72      6980\n",
      "         1.0       0.72      0.85      0.78      7159\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.76      0.75      0.75     14139\n",
      "weighted avg       0.76      0.75      0.75     14139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size=50, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_pred_bool))\n",
    "print(classification_report(y_test, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was my most complex model, yet it still did barely any better than the first model. It achieved an accurcy over 75%. Its recall for the target variable was 85%. This means that 85% of actual positives diabetes that were identified correctly. The Precision was much worse at 72%, meaning 72% of diabetes identifications that are actually correct. THe Precision for not diabetes is 81%, which is very good, but the recall is 65%. Overall the model is not horrible, but as it is the best performing model, it will proceed to the next stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying mutiple sets of Nueral Network models, I believe that 75% accuracy is the best accuracy that can be achieved with data of this size and complexity. I will now take the best model (Model 3) and fit it to the whole evenly split data. From there I will then under and Oversample the full dataset and see how the model performs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Unbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/Week7/diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "# Converting variables that were floats to integers for analysis \n",
    "data['Diabetes_binary'] = data['Diabetes_binary'].astype(int)\n",
    "data['HighBP'] = data['HighBP'].astype(int)\n",
    "data['HighChol'] = data['HighChol'].astype(int)\n",
    "data['CholCheck'] = data['CholCheck'].astype(int)\n",
    "data['Smoker'] = data['Smoker'].astype(int)\n",
    "data['Stroke'] = data['Stroke'].astype(int)\n",
    "data['HeartDiseaseorAttack'] = data['HeartDiseaseorAttack'].astype(int)\n",
    "data['PhysActivity'] = data['PhysActivity'].astype(int)\n",
    "data['Fruits'] = data['Fruits'].astype(int)\n",
    "data['Veggies'] = data['Veggies'].astype(int)\n",
    "data['HvyAlcoholConsump'] = data['HvyAlcoholConsump'].astype(int)\n",
    "data['AnyHealthcare'] = data['AnyHealthcare'].astype(int)\n",
    "data['NoDocbcCost'] = data['NoDocbcCost'].astype(int)\n",
    "data['GenHlth'] = data['GenHlth'].astype(int)\n",
    "data['MentHlth'] = data['MentHlth'].astype(int)\n",
    "data['PhysHlth'] = data['PhysHlth'].astype(int)\n",
    "data['DiffWalk'] = data['DiffWalk'].astype(int)\n",
    "data['Sex'] = data['Sex'].astype(int)\n",
    "data['Age'] = data['Age'].astype(int)\n",
    "data['Education'] = data['Education'].astype(int)\n",
    "data['Income'] = data['Income'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    218334\n",
       "1     35346\n",
       "Name: Diabetes_binary, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Diabetes_binary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will first be fit to the evenly split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data50[\"Diabetes_binary\"]\n",
    "X = data50.drop(\"Diabetes_binary\", axis=1)\n",
    "\n",
    "# Model 3\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=21, activation='sigmoid')) # Default activation is relu\n",
    "model.add(Dense(400, activation='sigmoid'))\n",
    "model.add(Dense(400, activation='sigmoid'))\n",
    "model.add(Dense(400, activation='sigmoid'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=keras.optimizers.RMSprop(), #default learning rate = 0.001\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "history_scaled = model.fit(X, y, batch_size = 50, epochs = 100, use_multiprocessing=True, callbacks=[Callback()], verbose=0) # default max iterations are 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling \n",
    "This is a technique used to balance uneven datasets by keeping all of the data in the minority class and decreasing the size of the majority class.\n",
    "\n",
    "I will used the original unbalanced data to predict on and see how well this model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1414/1414 [==============================] - 7s 5ms/step\n",
      "[[25418  9928]\n",
      " [ 7401 27945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75     35346\n",
      "           1       0.74      0.79      0.76     35346\n",
      "\n",
      "    accuracy                           0.75     70692\n",
      "   macro avg       0.76      0.75      0.75     70692\n",
      "weighted avg       0.76      0.75      0.75     70692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = data[\"Diabetes_binary\"]\n",
    "X_test = data.drop(\"Diabetes_binary\", axis=1)\n",
    "\n",
    "undersample = RandomUnderSampler(sampling_strategy=\"majority\")\n",
    "X_over, y_over = undersample.fit_resample(X, y)\n",
    "\n",
    "y_pred = model.predict(X_over, batch_size=50, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(metrics.confusion_matrix(y_over, y_pred_bool))\n",
    "print(classification_report(y_over, y_pred_bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the original data was undersampled, the model was still only able to achieve an accuracy of about 75%. The Precision for diabetes was only 74%, and the Recall was 79%. Overall, these scores are alright. Next we will test is oversampling has any noticable differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling\n",
    "The process of sampling a signal at a sampling frequency significantly higher than the Nyquist rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25418  9928]\n",
      " [ 7401 27945]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.72      0.75     35346\n",
      "           1       0.74      0.79      0.76     35346\n",
      "\n",
      "    accuracy                           0.75     70692\n",
      "   macro avg       0.76      0.75      0.75     70692\n",
      "weighted avg       0.76      0.75      0.75     70692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "\n",
    "#y_pred = model.predict(X_over, batch_size=64, verbose=1)\n",
    "#y_pred_bool = y_pred.astype(int).tolist() \n",
    "\n",
    "Y_pred = np.argmax(model.predict(X_over),axis=1)\n",
    "\n",
    "print(metrics.confusion_matrix(y_over, Y_pred))\n",
    "print(classification_report(y_over, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling achieved the exact same scores as Undersampling. I believe that this dataset is too massive and complex that it is difficult for the models to accurately predict diabetes well. Overall, 75% accuracy is good for a massive dataset this complex. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

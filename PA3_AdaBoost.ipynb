{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Activity - AdaBoost\n",
    "## Nick Bias\n",
    "### 4/22/22\n",
    "## Goal: Predict Penguin Species\n",
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For AdaBoosting Models\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For Comparision Models\n",
    "# compare standalone models for binary classification\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For splitting data into training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "# example of calculate the mean absolute error\n",
    "#from sklearn.metrics import accur\n",
    "\n",
    "# So results are same when re-run\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>344 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3    Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "339  Gentoo     Biscoe               NaN              NaN                NaN   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "3            NaN     NaN  \n",
       "4         3450.0  FEMALE  \n",
       "..           ...     ...  \n",
       "339          NaN     NaN  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[344 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lter = pd.read_csv(\"Data/Week4/penguins_lter.csv\")\n",
    "size = pd.read_csv(\"Data/Week4/penguins_size.csv\")\n",
    "#penguin = pd.merge(lter, size, left_index=True, right_index=True)\n",
    "#penguin.head\n",
    "size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are quite a few NaN values in the cells. Since most of the variables in these rows have NaNs, we should probably just drop these rows from the dataset, since they will not be useful for analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>Biscoe</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1    Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2    Adelie  Torgersen              40.3             18.0              195.0   \n",
       "4    Adelie  Torgersen              36.7             19.3              193.0   \n",
       "5    Adelie  Torgersen              39.3             20.6              190.0   \n",
       "..      ...        ...               ...              ...                ...   \n",
       "338  Gentoo     Biscoe              47.2             13.7              214.0   \n",
       "340  Gentoo     Biscoe              46.8             14.3              215.0   \n",
       "341  Gentoo     Biscoe              50.4             15.7              222.0   \n",
       "342  Gentoo     Biscoe              45.2             14.8              212.0   \n",
       "343  Gentoo     Biscoe              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g     sex  \n",
       "0         3750.0    MALE  \n",
       "1         3800.0  FEMALE  \n",
       "2         3250.0  FEMALE  \n",
       "4         3450.0  FEMALE  \n",
       "5         3650.0    MALE  \n",
       "..           ...     ...  \n",
       "338       4925.0  FEMALE  \n",
       "340       4850.0  FEMALE  \n",
       "341       5750.0    MALE  \n",
       "342       5200.0  FEMALE  \n",
       "343       5400.0    MALE  \n",
       "\n",
       "[333 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop Rows with NA values \n",
    "clean = size.dropna()\n",
    "\n",
    "# Drops row with a '.' for the Sex Variable\n",
    "clean = clean[clean['sex'] != '.']\n",
    "\n",
    "clean\n",
    "# only 11 rows were dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "      <th>MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie              39.1             18.7              181.0   \n",
       "1    Adelie              39.5             17.4              186.0   \n",
       "2    Adelie              40.3             18.0              195.0   \n",
       "4    Adelie              36.7             19.3              193.0   \n",
       "5    Adelie              39.3             20.6              190.0   \n",
       "..      ...               ...              ...                ...   \n",
       "338  Gentoo              47.2             13.7              214.0   \n",
       "340  Gentoo              46.8             14.3              215.0   \n",
       "341  Gentoo              50.4             15.7              222.0   \n",
       "342  Gentoo              45.2             14.8              212.0   \n",
       "343  Gentoo              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g  Biscoe  Dream  Torgersen  MALE  \n",
       "0         3750.0       0      0          1     1  \n",
       "1         3800.0       0      0          1     0  \n",
       "2         3250.0       0      0          1     0  \n",
       "4         3450.0       0      0          1     0  \n",
       "5         3650.0       0      0          1     1  \n",
       "..           ...     ...    ...        ...   ...  \n",
       "338       4925.0       1      0          0     0  \n",
       "340       4850.0       1      0          0     0  \n",
       "341       5750.0       1      0          0     1  \n",
       "342       5200.0       1      0          0     0  \n",
       "343       5400.0       1      0          0     1  \n",
       "\n",
       "[333 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dummy Variables for Island and Sex\n",
    "island = pd.get_dummies(clean['island'])\n",
    "sex = pd.get_dummies(clean['sex'])\n",
    "\n",
    "# Merging with Original Data\n",
    "penguins = pd.merge(clean, island, left_index=True, right_index=True)\n",
    "penguins = pd.merge(penguins, sex, left_index=True, right_index=True)\n",
    "\n",
    "# Dropping Columns that the Dummies were made from \n",
    "penguins = penguins.drop(['sex', 'island', 'FEMALE'], axis = 1)\n",
    "penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Final Dataset that will be used for Analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Prediction Variable from dataset\n",
    "- X = Dataset with all Independent Variables \n",
    "- y = The Dependent Variable of Penguin Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Takes Dependent Variable we are tryng to predict \n",
    "y = penguins['species']\n",
    "\n",
    "# Takes independent variables that will be used to predict \n",
    "X = penguins.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Models to Compare with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', BaggingClassifier(base_estimator=LogisticRegression())))\n",
    "    level0.append(('knn', BaggingClassifier(base_estimator=KNeighborsClassifier())))\n",
    "    level0.append(('cart', BaggingClassifier(base_estimator=DecisionTreeClassifier())))\n",
    "    level0.append(('forest', BaggingClassifier(base_estimator=RandomForestClassifier())))\n",
    "    level0.append(('svm', BaggingClassifier(base_estimator=SVC())))\n",
    "    level0.append(('bayes', BaggingClassifier(base_estimator=GaussianNB())))\n",
    "    level0.append(('boost', BaggingClassifier(base_estimator=AdaBoostClassifier())))\n",
    "    # define meta learner model\n",
    "    level1 = DecisionTreeClassifier()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, passthrough = True)\n",
    "    return model\n",
    "# passthrough is used for the stacking to take the og dataset instead of just the other model results\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['cart'] = DecisionTreeClassifier()\n",
    "    models['forest'] = RandomForestClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    models['boost'] = AdaBoostClassifier()\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.988 (0.017)\n",
      ">knn 0.792 (0.043)\n",
      ">cart 0.977 (0.023)\n",
      ">forest 0.992 (0.015)\n",
      ">svm 0.724 (0.038)\n",
      ">bayes 0.841 (0.059)\n",
      ">boost 0.813 (0.067)\n",
      ">stacking 0.981 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best Models were the Decision Tree and Random Forest Models. AdaBoosting was the 6th best model out of 8 models. This may have been because the parameters have not been tuned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset into a Training and Testing set \n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is:  97.01492537313433 %\n"
     ]
    }
   ],
   "source": [
    "AdaBoost = AdaBoostClassifier(n_estimators=100,learning_rate=0.2, algorithm='SAMME')\n",
    "    \n",
    "AdaBoost.fit(x_train, y_train)\n",
    "\n",
    "prediction = AdaBoost.score(x_test,y_test)\n",
    "\n",
    "print('The accuracy is: ',prediction*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 accuracy is:  73.13432835820896 %\n",
      "Model 1 accuracy is:  98.50746268656717 %\n",
      "Model 2 accuracy is:  65.67164179104478 %\n",
      "Model 3 accuracy is:  95.52238805970148 %\n",
      "Model 4 accuracy is:  37.3134328358209 %\n",
      "Model 5 accuracy is:  98.50746268656717 %\n",
      "Model 6 accuracy is:  95.52238805970148 %\n"
     ]
    }
   ],
   "source": [
    "# Model 0 - default parameters\n",
    "AdaBoost0 = AdaBoostClassifier()\n",
    "AdaBoost0.fit(x_train, y_train)\n",
    "prediction0 = AdaBoost0.score(x_test,y_test)\n",
    "\n",
    "# Model 1 - High parameters \n",
    "AdaBoost1 = AdaBoostClassifier(n_estimators=400,\n",
    "                               learning_rate=1, algorithm='SAMME')\n",
    "AdaBoost1.fit(x_train, y_train)\n",
    "prediction1 = AdaBoost1.score(x_test,y_test)\n",
    "\n",
    "# Model 2 - Low estimators and learning rate \n",
    "AdaBoost2 = AdaBoostClassifier(n_estimators=5,\n",
    "                               learning_rate=0.1, algorithm='SAMME')\n",
    "AdaBoost2.fit(x_train, y_train)\n",
    "prediction2 = AdaBoost2.score(x_test,y_test)\n",
    "\n",
    "# Model 3 - Low learning rate \n",
    "AdaBoost3 = AdaBoostClassifier(n_estimators=100,\n",
    "                               learning_rate=0.1, algorithm='SAMME')\n",
    "AdaBoost3.fit(x_train, y_train)\n",
    "prediction3 = AdaBoost3.score(x_test,y_test)\n",
    "\n",
    "# Model 4 - New SVC model, high estimators and learning rate\n",
    "AdaBoost4 = AdaBoostClassifier(base_estimator= SVC(), \n",
    "                               n_estimators=400,\n",
    "                               learning_rate=1, algorithm='SAMME')\n",
    "AdaBoost4.fit(x_train, y_train)\n",
    "prediction4 = AdaBoost4.score(x_test,y_test)\n",
    "\n",
    "base_estimator=RandomForestClassifier()\n",
    "\n",
    "# Model 5 - New Random Forest model \n",
    "AdaBoost5 = AdaBoostClassifier(base_estimator=RandomForestClassifier())\n",
    "AdaBoost5.fit(x_train, y_train)\n",
    "prediction5 = AdaBoost5.score(x_test,y_test)\n",
    "\n",
    "# Model 6 - Decision Tree \n",
    "AdaBoost6 = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(),\n",
    "                               n_estimators=100,\n",
    "                               learning_rate=0.5, algorithm='SAMME')\n",
    "AdaBoost6.fit(x_train, y_train)\n",
    "prediction6 = AdaBoost6.score(x_test,y_test)\n",
    "\n",
    "print('Model 0 accuracy is: ',prediction0*100,'%')\n",
    "print('Model 1 accuracy is: ',prediction1*100,'%')\n",
    "print('Model 2 accuracy is: ',prediction2*100,'%')\n",
    "print('Model 3 accuracy is: ',prediction3*100,'%')\n",
    "print('Model 4 accuracy is: ',prediction4*100,'%')\n",
    "print('Model 5 accuracy is: ',prediction5*100,'%')\n",
    "print('Model 6 accuracy is: ',prediction6*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 0 is a Baseline model with default perameters. This will be what the other models are compared with. \n",
    "- Model 1 has High n-estimators and Learning Rate. A higher learning rate increases the contribution of each classifier. High n-estimators means much more weak learners are used in the next training iteration. This achieved one of the best accuracy scores. \n",
    "- Model 2 has low n-estimators and Learning Rate. This is basically the opposite of Model 2. Classifiers have less contribution and not many weak learners are trained in the next iteration. Its accuracy is decent.\n",
    "- Model 3 has a low learning rate and still achieved one of the best accuracy scores. \n",
    "- Model 4 uses a Support Vector Classifier model and high estimators and learning rate. It performed the worst out of all the models.\n",
    "- Model 5 uses a Random Forest Model with default perameters. It is one of the best performing models.\n",
    "- Model 6 uses a Decision Tree Model with high estimators and less learning rate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

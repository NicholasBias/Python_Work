{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Activity - Neural Networks\n",
    "## Nick Bias\n",
    "### 5/6/22\n",
    "## Goal: Predict Penguin Species\n",
    "### Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For Neural Networks \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# For Boosting \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# For Comparision Models\n",
    "# compare standalone models for binary classification\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# For splitting data into training and testing \n",
    "from sklearn.model_selection import train_test_split\n",
    "# example of calculate the mean absolute error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# For Evaluations \n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# for viewing PNG files \n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# So results are same when re-run\n",
    "import random\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>Biscoe</th>\n",
       "      <th>Dream</th>\n",
       "      <th>Torgersen</th>\n",
       "      <th>MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>47.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>214.0</td>\n",
       "      <td>4925.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>46.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4850.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>50.4</td>\n",
       "      <td>15.7</td>\n",
       "      <td>222.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>45.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>212.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Gentoo</td>\n",
       "      <td>49.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>213.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>333 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    species  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0    Adelie              39.1             18.7              181.0   \n",
       "1    Adelie              39.5             17.4              186.0   \n",
       "2    Adelie              40.3             18.0              195.0   \n",
       "4    Adelie              36.7             19.3              193.0   \n",
       "5    Adelie              39.3             20.6              190.0   \n",
       "..      ...               ...              ...                ...   \n",
       "338  Gentoo              47.2             13.7              214.0   \n",
       "340  Gentoo              46.8             14.3              215.0   \n",
       "341  Gentoo              50.4             15.7              222.0   \n",
       "342  Gentoo              45.2             14.8              212.0   \n",
       "343  Gentoo              49.9             16.1              213.0   \n",
       "\n",
       "     body_mass_g  Biscoe  Dream  Torgersen  MALE  \n",
       "0         3750.0       0      0          1     1  \n",
       "1         3800.0       0      0          1     0  \n",
       "2         3250.0       0      0          1     0  \n",
       "4         3450.0       0      0          1     0  \n",
       "5         3650.0       0      0          1     1  \n",
       "..           ...     ...    ...        ...   ...  \n",
       "338       4925.0       1      0          0     0  \n",
       "340       4850.0       1      0          0     0  \n",
       "341       5750.0       1      0          0     1  \n",
       "342       5200.0       1      0          0     0  \n",
       "343       5400.0       1      0          0     1  \n",
       "\n",
       "[333 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = pd.read_csv(\"Data/Week4/penguins_size.csv\")\n",
    "\n",
    "# Drop Rows with NA values \n",
    "clean = size.dropna()\n",
    "\n",
    "# Drops row with a '.' for the Sex Variable\n",
    "clean = clean[clean['sex'] != '.']\n",
    "# only 11 rows were dropped \n",
    "\n",
    "# Creating Dummy Variables for Island and Sex\n",
    "island = pd.get_dummies(clean['island'])\n",
    "sex = pd.get_dummies(clean['sex'])\n",
    "\n",
    "# Merging with Original Data\n",
    "penguins = pd.merge(clean, island, left_index=True, right_index=True)\n",
    "penguins = pd.merge(penguins, sex, left_index=True, right_index=True)\n",
    "\n",
    "# Dropping Columns that the Dummies were made from \n",
    "penguins = penguins.drop(['sex', 'island', 'FEMALE'], axis = 1)\n",
    "penguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Prediction Variable from dataset\n",
    "- X = Dataset with all Independent Variables \n",
    "- y = The Dependent Variable of Penguin Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only Takes Dependent Variable we are tryng to predict \n",
    "y = penguins['species']\n",
    "\n",
    "# Change levels to numeric for XGBoosting \n",
    "y = y.replace('Adelie', 0)\n",
    "y = y.replace('Chinstrap', 1)\n",
    "y = y.replace('Gentoo', 2)\n",
    "# 'Adelie' 'Chinstrap' 'Gentoo'\n",
    "\n",
    "# Takes independent variables that will be used to predict \n",
    "X = penguins.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', BaggingClassifier(base_estimator=LogisticRegression())))\n",
    "    level0.append(('knn', BaggingClassifier(base_estimator=KNeighborsClassifier())))\n",
    "    level0.append(('tree', BaggingClassifier(base_estimator=DecisionTreeClassifier())))\n",
    "    level0.append(('forest', BaggingClassifier(base_estimator=RandomForestClassifier())))\n",
    "    level0.append(('svm', BaggingClassifier(base_estimator=SVC())))\n",
    "    level0.append(('bayes', BaggingClassifier(base_estimator=GaussianNB())))\n",
    "    level0.append(('adaboost', BaggingClassifier(base_estimator=AdaBoostClassifier())))\n",
    "    level0.append(('gradboost', BaggingClassifier(base_estimator=GradientBoostingClassifier())))\n",
    "    level0.append(('xgboost', BaggingClassifier(base_estimator=XGBClassifier())))\n",
    "    level0.append(('nueralNet', BaggingClassifier(base_estimator=MLPClassifier(random_state=1))))\n",
    "    # define meta learner model\n",
    "    level1 = DecisionTreeClassifier()\n",
    "    # define the stacking ensemble\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5, passthrough = True)\n",
    "    return model\n",
    "# passthrough is used for the stacking to take the og dataset instead of just the other model results\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    models['lr'] = LogisticRegression()\n",
    "    models['knn'] = KNeighborsClassifier()\n",
    "    models['tree'] = DecisionTreeClassifier()\n",
    "    models['forest'] = RandomForestClassifier()\n",
    "    models['svm'] = SVC()\n",
    "    models['bayes'] = GaussianNB()\n",
    "    models['adaboost'] = AdaBoostClassifier()\n",
    "    models['gradboost'] = GradientBoostingClassifier()\n",
    "    models['xgboost'] = XGBClassifier()\n",
    "    models['nueralNet'] = MLPClassifier(random_state=1)\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.988 (0.017)\n",
      ">knn 0.792 (0.043)\n",
      ">tree 0.980 (0.020)\n",
      ">forest 0.992 (0.015)\n",
      ">svm 0.724 (0.038)\n",
      ">bayes 0.841 (0.059)\n",
      ">adaboost 0.813 (0.067)\n",
      ">gradboost 0.986 (0.017)\n",
      ">xgboost 0.988 (0.017)\n",
      ">nueralNet 0.398 (0.078)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that out of the 10 different default Models, 5 were able to achieve accuracy scores above 97%. These models were Logistic Regression, Decision Tree, Random Forest, Gradient Boost, and XG Boost. Naive Bayes and AdaBoost had Accuracies around 80%, while KNN and SVM had accuracies around 75%. These all did much better compared to a default Nueral Network. It has an Accuracy about 40%, which is the worst out of all the models. This is horrible accuracy compared to every other model. Even SVM accuracy, which had the second worst accuracy, was 32.6% higher than the Nueral Network. Further tunning will need to be done to make a decent Nueral Network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Dataset into a Training and Testing set \n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To have consistent resutls, I will have each model have \"random_state=1\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Accuracy: 43.28%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Base Model Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a base Neural Metwork Model only has an accuracy of 43.28%. This is very bad. We would at least like this to be above 75%. I will use the SciKit Learn documentation website to find parameters to tune. I will mess around with these until I notice a difference in the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy: 41.79%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, solver='sgd', learning_rate='invscaling', power_t=1, max_iter=500)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 1 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this second Model, I changed the solver to ‘sgd’ which refers to stochastic gradient descent. From there, I changed the learning rate to 'invscaling'. This means the model will gradually decrease the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. Because of this I added power t. It is the exponent for inverse scaling learning rate. It is used in updating effective learning rate when the learning_rate is set to ‘invscaling’ and can only used when solver=’sgd’. I then made max iterations 500. OVerall, this made the Model 1 perform slightly worse then the base model, with an accuracy of 41.79%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Accuracy: 32.84%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 2 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2 had a 'lbfgs' solver. This is an optimizer in the family of quasi-Newton methods.The alpha was then set to 0.00001, which is the L2 penalty (regularization term) parameter. It has an architecture of 2 hideen layers with the first layer having 5 nodes, while the second layer has 2. In the end, this made Model 2 perform worse than the previous 2 models with an accuracy of 32.84%, which is more than 10% less than the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 3 Accuracy: 25.37%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, hidden_layer_sizes=(400,100,50,5), alpha=0.01)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 3 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Model 3, I messed with the Hidden Layer sizes. I gave it 4 hidden layers. The first layer had 400 nodes, the second had 100, the third had 50, and the four and final hidden layer had 5 nodes. The alpha was then set to 0.01. This made the worst performing model out of all the Neural Networks tested, with an accuracy of 25.37%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 Accuracy: 58.21%\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(base_estimator=MLPClassifier(random_state=1), random_state=1)\n",
    "bag.fit(x_train, y_train)\n",
    "\n",
    "y_pred = bag.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 4 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Model 4, I decided to Bag a base Neural Network model to see if this would imporve anything. To my surprise, it increase accuracy by almost 15%. This is the best performing model so far. For my Final Model I will make sure to use bagging to increase performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5 Accuracy: 56.72%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=200, activation='logistic', learning_rate_init=0.0005)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 5 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Model 5, I increased the base max iterations from 100 to 200. This solver iterates until convergence (determined by ‘tol’) or this number of iterations. I then changed activation to 'logistic', which uses the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)). I then decreased the inital learning rate, which controls the step-size in updating the weights. This Model had increrased performance from the base model, with an accuracy of 56.72%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 6 Accuracy: 73.13%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, \n",
    "                    max_iter=300, \n",
    "                    activation='logistic', \n",
    "                    learning_rate_init=0.002, \n",
    "                    hidden_layer_sizes=(400,), \n",
    "                    alpha=0.001)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 6 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6 achieved an accuracy of 73.13%. Its maximum iterations were set to 300. It used a logistic activation, with an inital learning rate of 0.002. Its architecture has only 1 hidden layer with 400 nodes in it. The alpha was then set to 0.001. Overall, this is performing alright, but we can still try to make a better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 7 Accuracy: 92.54%\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(base_estimator=MLPClassifier(random_state=1, \n",
    "                                                     solver='lbfgs',\n",
    "                                                     max_iter=300, \n",
    "                                                     activation='logistic', \n",
    "                                                     learning_rate_init=0.00065, \n",
    "                                                     hidden_layer_sizes=(400,400), \n",
    "                                                     alpha=0.01), random_state=1)\n",
    "bag.fit(x_train, y_train)\n",
    "\n",
    "y_pred = bag.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Model 7 Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 6 uses many features of the old models and adds to them. I first bagged the model, as I noticed this helped performance earlier. Its architecture is 2 hidden layers with 400 nodes in each. Its solver was set to 'lbfgs', with 300 maximum iterations, a logistic activation function, an inital learning rate of 0.00065 and an alpha of 0.01. All these parameters helped this model achieve an accuracy above 90%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "bag = BaggingClassifier(base_estimator=MLPClassifier(random_state=1, \n",
    "                                                     solver='lbfgs',\n",
    "                                                     max_iter=300, \n",
    "                                                     activation='logistic', \n",
    "                                                     learning_rate_init=0.00065, \n",
    "                                                     hidden_layer_sizes=(400,), \n",
    "                                                     alpha=0.01), random_state=1)\n",
    "bag.fit(x_train, y_train)\n",
    "\n",
    "y_pred = bag.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Final Model Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my Final Model, I used everything that I learned in the previous models. I put in all the parameters that I noticed would increase the accuracy of a model. Because of this, the Final Model had an amazing accuracy of 100%. This is almost a 57% increase in accuracy compared to the base model. This may indicate that the Model is overfitting the data, however, this dataset is rather small, with only 67 observations in the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  0 28]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the Confusion Matrix of the final model and see how it classified each spieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000        22\n",
      "           1      1.000     1.000     1.000        17\n",
      "           2      1.000     1.000     1.000        28\n",
      "\n",
      "    accuracy                          1.000        67\n",
      "   macro avg      1.000     1.000     1.000        67\n",
      "weighted avg      1.000     1.000     1.000        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the Precision and Recall of each class is at 100%. This means 100% of positive identifications that are actually correct and 100% of actual positives that were identified correctly. This Model seems to have no misclassification. If the dataset was larger we should investigate overfitting, but for now, this is a perfect model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.955     0.955     0.955        22\n",
      "           1      0.941     0.941     0.941        17\n",
      "           2      1.000     1.000     1.000        28\n",
      "\n",
      "    accuracy                          0.970        67\n",
      "   macro avg      0.965     0.965     0.965        67\n",
      "weighted avg      0.970     0.970     0.970        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(x_train, y_train)\n",
    "\n",
    "y_pred = forest.predict(x_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "print(metrics.classification_report(y_test, predictions, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Final Neural Network Model is now outperforming a base Random Forest Model, which has an accuracy of 97%. Its precision and recall scores range from 94% to 100%. This is a good model, however, the Neural Network model had to go throguh a great deal of tuning to outperform this base level Random Forest Model. I am sure with some tuning in the Random Forest Model, it will be able to achieve an accuracy of 100%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Archecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not know why but the images will not appear in the HTML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model and Models 1, 4, & 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Data/Week6/NN_Arch1.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Data/Week6/NN_Arch1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Data/Week6/NN_Arch2.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Data/Week6/NN_Arch2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Data/Week6/NN_Arch3.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Data/Week6/NN_Arch3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Data/Week6/NN_Arch5.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Data/Week6/NN_Arch5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6 and Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"Data/Week6/NN_Arch4.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"Data/Week6/NN_Arch4.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
